{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderdouri/PINNs/blob/master/Tutorials/IPINN_Navier_Stokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Helper function for gradient computation\n",
        "def gradients(y, x):\n",
        "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "# Define the PINN model\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PINN, self).__init__()\n",
        "        self.hidden_layers = nn.Sequential(\n",
        "            nn.Linear(3, 50),  # Input: (t, x, y)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 3)   # Output: (v_x, v_y, p)\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x, y):\n",
        "        inputs = torch.cat([t, x, y], dim=1)\n",
        "        return self.hidden_layers(inputs)\n",
        "\n",
        "# Define the unknown parameters (C1 and C2)\n",
        "log_C1 = torch.tensor([0.0], requires_grad=True, dtype=torch.float32)  # log(C1) for positivity\n",
        "log_C2 = torch.tensor([0.0], requires_grad=True, dtype=torch.float32)  # log(C2) for positivity\n",
        "\n",
        "# Initialize the model\n",
        "model = PINN()\n",
        "\n",
        "# Loss function\n",
        "def loss_function(t, x, y, v_obs, p_obs):\n",
        "    C1 = torch.exp(log_C1)\n",
        "    C2 = torch.exp(log_C2)\n",
        "\n",
        "    # Ensure gradients can be computed\n",
        "    t.requires_grad_(True)\n",
        "    x.requires_grad_(True)\n",
        "    y.requires_grad_(True)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(t, x, y)\n",
        "    v_x, v_y, p = output[:, 0:1], output[:, 1:2], output[:, 2:3]\n",
        "\n",
        "    # Compute derivatives\n",
        "    v_x_t = gradients(v_x, t)\n",
        "    v_x_x = gradients(v_x, x)\n",
        "    v_x_y = gradients(v_x, y)\n",
        "    v_xx = gradients(v_x_x, x)\n",
        "    v_yy = gradients(v_x_y, y)\n",
        "\n",
        "    v_y_t = gradients(v_y, t)\n",
        "    v_y_x = gradients(v_y, x)\n",
        "    v_y_y = gradients(v_y, y)\n",
        "    v_yx = gradients(v_y_x, x)\n",
        "    v_yy = gradients(v_y_y, y)\n",
        "\n",
        "    p_x = gradients(p, x)\n",
        "    p_y = gradients(p, y)\n",
        "\n",
        "    # Residuals of Navier-Stokes equations\n",
        "    f_vx = v_x_t + C1 * (v_x * v_x_x + v_y * v_x_y) + p_x - C2 * (v_xx + v_yy)\n",
        "    f_vy = v_y_t + C1 * (v_x * v_y_x + v_y * v_y_y) + p_y - C2 * (v_yx + v_yy)\n",
        "\n",
        "    # Physics-based loss\n",
        "    physics_loss = torch.mean(f_vx**2) + torch.mean(f_vy**2)\n",
        "\n",
        "    # Data loss (mean squared error with observed data)\n",
        "    data_loss = torch.mean((v_x - v_obs[:, 0:1])**2) + \\\n",
        "                torch.mean((v_y - v_obs[:, 1:2])**2) + \\\n",
        "                torch.mean((p - p_obs)**2)\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = physics_loss + data_loss\n",
        "    return total_loss\n",
        "\n",
        "# Optimizer for both model parameters and unknown constants\n",
        "optimizer = optim.Adam(list(model.parameters()) + [log_C1, log_C2], lr=0.001)\n",
        "\n",
        "# Training data (replace with actual data)\n",
        "n_points = 1000\n",
        "x_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "y_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "t_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "v_train = torch.cat([torch.sin(torch.pi * x_train), torch.cos(torch.pi * y_train)], dim=1)  # Example: true velocities\n",
        "p_train = torch.zeros_like(x_train)  # Example: true pressure\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 2000\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(t_train, x_train, y_train, v_train, p_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, C1: {torch.exp(log_C1).item():.6f}, C2: {torch.exp(log_C2).item():.6f}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print(f\"Learned C1: {torch.exp(log_C1).item():.6f}\")\n",
        "print(f\"Learned C2: {torch.exp(log_C2).item():.6f}\")\n"
      ],
      "metadata": {
        "id": "tqWaKj70eyfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}