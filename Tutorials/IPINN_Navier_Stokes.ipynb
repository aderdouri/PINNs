{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderdouri/PINNs/blob/master/Tutorials/IPINN_Navier_Stokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import scipy.io\n",
        "import torch\n",
        "import io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "lpWIHXFdqT5Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_data(num):\n",
        "    # Changed to raw URL\n",
        "    url = \"https://github.com/maziarraissi/PINNs/raw/master/main/Data/cylinder_nektar_wake.mat\"\n",
        "    # Step 2: Download the file content\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Ensure the request was successful\n",
        "    # Step 3: Load the .mat file into memory\n",
        "    data = scipy.io.loadmat(io.BytesIO(response.content))\n",
        "\n",
        "    U_star = data[\"U_star\"]  # N x 2 x T\n",
        "    P_star = data[\"p_star\"]  # N x T\n",
        "    t_star = data[\"t\"]  # T x 1\n",
        "    X_star = data[\"X_star\"]  # N x 2\n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    # Rearrange Data\n",
        "    XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
        "    YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
        "    TT = np.tile(t_star, (1, N)).T  # N x T\n",
        "    UU = U_star[:, 0, :]  # N x T\n",
        "    VV = U_star[:, 1, :]  # N x T\n",
        "    PP = P_star  # N x T\n",
        "    x = XX.flatten()[:, None]  # NT x 1\n",
        "    y = YY.flatten()[:, None]  # NT x 1\n",
        "    t = TT.flatten()[:, None]  # NT x 1\n",
        "    u = UU.flatten()[:, None]  # NT x 1\n",
        "    v = VV.flatten()[:, None]  # NT x 1\n",
        "    p = PP.flatten()[:, None]  # NT x 1\n",
        "    # training domain: X × Y = [1, 8] × [−2, 2] and T = [0, 7]\n",
        "    data1 = np.concatenate([x, y, t, u, v, p], 1)\n",
        "    data2 = data1[:, :][data1[:, 2] <= 7]\n",
        "    data3 = data2[:, :][data2[:, 0] >= 1]\n",
        "    data4 = data3[:, :][data3[:, 0] <= 8]\n",
        "    data5 = data4[:, :][data4[:, 1] >= -2]\n",
        "    data_domain = data5[:, :][data5[:, 1] <= 2]\n",
        "    # choose number of training points: num =7000\n",
        "    idx = np.random.choice(data_domain.shape[0], num, replace=False)\n",
        "    x_train = data_domain[idx, 0:1]\n",
        "    y_train = data_domain[idx, 1:2]\n",
        "    t_train = data_domain[idx, 2:3]\n",
        "    u_train = data_domain[idx, 3:4]\n",
        "    v_train = data_domain[idx, 4:5]\n",
        "    p_train = data_domain[idx, 5:6]\n",
        "    return [x_train, y_train, t_train, u_train, v_train, p_train]"
      ],
      "metadata": {
        "id": "8TP2NS-aqYle"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "def loss_function(x, y, t, u_obs, v_obs, p_obs):\n",
        "    C1 = torch.exp(log_C1)\n",
        "    C2 = torch.exp(log_C2)\n",
        "\n",
        "    # Ensure gradients can be computed\n",
        "    t.requires_grad_(True)\n",
        "    x.requires_grad_(True)\n",
        "    y.requires_grad_(True)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(x, y, t)\n",
        "    u_pred, v_pred, p_pred = output[:, 0:1], output[:, 1:2], output[:, 2:3]\n",
        "\n",
        "    # Compute derivatives\n",
        "    u_t = gradients(u_pred, t)\n",
        "    u_x = gradients(u_pred, x)\n",
        "    u_y = gradients(u_pred, y)\n",
        "    u_xx = gradients(u_x, x)\n",
        "    u_yy = gradients(u_y, y)\n",
        "\n",
        "    v_t = gradients(v_pred, t)\n",
        "    v_x = gradients(v_pred, x)\n",
        "    v_y = gradients(v_pred, y)\n",
        "    v_xx = gradients(v_x, x)\n",
        "    v_yy = gradients(v_y, y)\n",
        "\n",
        "    p_x = gradients(p_pred, x)\n",
        "    p_y = gradients(p_pred, y)\n",
        "\n",
        "    # Residuals of Navier-Stokes equations\n",
        "    f_u = u_t + C1 * (u_pred * u_x + v_pred * u_y) + p_x - C2 * (u_xx + u_yy)\n",
        "    f_v = v_t + C1 * (u_pred * v_x + v_pred * v_y) + p_y - C2 * (v_xx + v_yy)\n",
        "\n",
        "    # Continuity equation\n",
        "    f_cont = gradients(u_pred, x) + gradients(v_pred, y)\n",
        "\n",
        "    # Physics-based loss\n",
        "    physics_loss = torch.mean(f_u**2) + torch.mean(f_v**2) + torch.mean(f_cont**2)\n",
        "\n",
        "    # Data loss (mean squared error with observed data)\n",
        "    data_loss = torch.mean((u_pred - u_obs)**2) + \\\n",
        "                torch.mean((v_pred - v_obs)**2) + \\\n",
        "                torch.mean((p_pred - p_obs)**2)\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = physics_loss + data_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "_5Gr5Q8esCfP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for gradient computation\n",
        "def gradients(y, x):\n",
        "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "# Define the PINN model\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PINN, self).__init__()\n",
        "        self.hidden_layers = nn.Sequential(\n",
        "            nn.Linear(3, 50),  # Input: (x, y, t)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(50, 3)   # Output: (v_x, v_y, p)\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x, y):\n",
        "        inputs = torch.cat([t, x, y], dim=1)\n",
        "        return self.hidden_layers(inputs)\n",
        "\n",
        "# Define the unknown parameters (C1 and C2)\n",
        "log_C1 = torch.tensor([0.0], requires_grad=True, dtype=torch.float32)  # log(C1) for positivity\n",
        "log_C2 = torch.tensor([0.0], requires_grad=True, dtype=torch.float32)  # log(C2) for positivity\n",
        "\n",
        "# Initialize the model\n",
        "model = PINN()"
      ],
      "metadata": {
        "id": "tqWaKj70eyfy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer for both model parameters and unknown constants\n",
        "optimizer = optim.Adam(list(model.parameters()) + [log_C1, log_C2], lr=0.001)\n",
        "\n",
        "# Training data (replace with actual data)\n",
        "#n_points = 1000\n",
        "#x_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "#y_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "#t_train = torch.rand(n_points, 1, requires_grad=True)\n",
        "#v_train = torch.cat([torch.sin(torch.pi * x_train), torch.cos(torch.pi * y_train)], dim=1)  # Example: true velocities\n",
        "#p_train = torch.zeros_like(x_train)  # Example: true pressure\n",
        "\n",
        "\n",
        "# Training data\n",
        "# Get the training data: num = 7000\n",
        "[x_train, y_train, t_train, u_train, v_train, p_train] = load_training_data(num=7000)\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32, requires_grad=True)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=True)\n",
        "t_train = torch.tensor(t_train, dtype=torch.float32, requires_grad=True)\n",
        "u_train = torch.tensor(u_train, dtype=torch.float32)\n",
        "v_train = torch.tensor(v_train, dtype=torch.float32)\n",
        "p_train = torch.tensor(p_train, dtype=torch.float32)\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 20000\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(x_train, y_train, t_train, u_train, v_train, p_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, C1: {torch.exp(log_C1).item():.6f}, C2: {torch.exp(log_C2).item():.6f}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print(f\"Learned C1: {torch.exp(log_C1).item():.6f}\")\n",
        "print(f\"Learned C2: {torch.exp(log_C2).item():.6f}\")"
      ],
      "metadata": {
        "id": "0Kw1lHHXqdhs",
        "outputId": "3d3d520e-4e0d-41ef-a45a-5bef48e9f687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.870026, C1: 1.001001, C2: 0.999000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-1_WW_lqvj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}