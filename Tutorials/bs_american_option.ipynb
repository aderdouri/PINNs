{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderdouri/PINNs/blob/master/Tutorials/bs_american_option.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BLAP2KL9b3y8",
        "outputId": "fab1d4d0-af1f-4759-f8ca-0ccc4e30f37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7de1b60a2eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackScholesMertonModel1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BlackScholesMertonModel1, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(2)\n",
        "        self.fc1 = nn.Linear(2, 50)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "        self.fc3 = nn.Linear(50, 50)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm1d(50)\n",
        "        self.fc4 = nn.Linear(50, 50)\n",
        "        self.act4 = nn.ReLU()\n",
        "        self.bn5 = nn.BatchNorm1d(50)\n",
        "        self.fc5 = nn.Linear(50, 50)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.bn6 = nn.BatchNorm1d(50)\n",
        "        self.fc6 = nn.Linear(50, 50)\n",
        "        self.act6 = nn.ReLU()\n",
        "        self.bn7 = nn.BatchNorm1d(50)\n",
        "        self.fc7 = nn.Linear(50, 50)\n",
        "        self.act7 = nn.ReLU()\n",
        "        self.bn8 = nn.BatchNorm1d(50)\n",
        "        self.fc8 = nn.Linear(50, 50)\n",
        "        self.act8 = nn.ReLU()\n",
        "        self.bn9 = nn.BatchNorm1d(50)\n",
        "        self.fc9 = nn.Linear(50, 50)\n",
        "        self.act9 = nn.ReLU()\n",
        "        self.bn10 = nn.BatchNorm1d(50)\n",
        "        self.fc10 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.act4(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.act5(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.act6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.act7(x)\n",
        "        x = self.fc8(x)\n",
        "        x = self.act8(x)\n",
        "        x = self.fc9(x)\n",
        "        x = self.act9(x)\n",
        "        x = self.fc10(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eVk_SonNweRT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from ExplicitEu import ExplicitEu\n",
        "#from ImplicitEu import ImplicitEu\n",
        "#from ImplicitAm import ImplicitAmBer\n",
        "#from ImplicitAm import ImplicitAmBre\n",
        "\n",
        "S0 = 100\n",
        "exercise_price = 100\n",
        "sigma = 0.4\n",
        "r = 0.03\n",
        "dividend = 0.00\n",
        "tau = 3\n",
        "M = 500  # S\n",
        "N = 600  # t\n",
        "Smax = 500\n",
        "is_call = True\n",
        "N_b = 100\n",
        "N_exp = 1000\n",
        "N_f = 10000\n",
        "lb = [0, 0]\n",
        "ub = [500, tau]\n",
        "\n",
        "t, S = np.meshgrid(np.linspace(0, 1, N + 1), np.linspace(0, Smax, M + 1))\n",
        "#option = ImplicitAmBer(S0, exercise_price, r, tau, sigma, Smax, M, N, is_call)\n",
        "#option.price()\n",
        "#option_fde_prices = option.grid\n",
        "\n",
        "def initialize_data(N_b, N_exp, N_f, lb, ub, exercise_price, tau):\n",
        "    # Data for collocation\n",
        "    stock_price_collocation = torch.randint(low=0, high=ub[0] + 1, size=(N_f, 1)).type(torch.FloatTensor)\n",
        "    time_collocation = (torch.randint(low=0, high=100 * ub[1] + 1, size=(N_f, 1)) / 100).type(torch.FloatTensor)\n",
        "\n",
        "    stock_price_mean = torch.mean(stock_price_collocation)\n",
        "    stock_price_std = torch.std(stock_price_collocation)\n",
        "    time_mean = torch.mean(time_collocation)\n",
        "    time_std = torch.std(time_collocation)\n",
        "\n",
        "    time_collocation = (time_collocation - time_mean) / time_std\n",
        "    stock_price_collocation = (stock_price_collocation - stock_price_mean) / stock_price_std\n",
        "\n",
        "    X_f = torch.cat((time_collocation, stock_price_collocation), 1)\n",
        "\n",
        "    # Data for boundary\n",
        "    time_boundary = (torch.randint(low=1, high=100 * ub[1] + 1, size=(N_b, 1)) / 100).type(torch.FloatTensor)\n",
        "    X_b = torch.cat((time_boundary, torch.zeros_like(time_boundary)), 1)\n",
        "\n",
        "    # Data for initial time\n",
        "    stock_price_exp = torch.randint(low=0, high=ub[0] + 1, size=(N_exp, 1)).type(torch.FloatTensor)\n",
        "    option_price_exp = stock_price_exp - exercise_price\n",
        "    u_exp = torch.Tensor([[max(instance, 0)] for instance in option_price_exp]).type(torch.FloatTensor)\n",
        "\n",
        "    X_exp = torch.cat((torch.full_like(stock_price_exp, tau), stock_price_exp), 1)\n",
        "\n",
        "    return X_f, X_f, X_b, X_exp, u_exp\n",
        "\n",
        "X_f, X_f_norm, X_b, X_exp, u_exp = initialize_data(N_b, N_exp, N_f, lb, ub, exercise_price, tau)\n",
        "\n",
        "u_collocation = []\n",
        "for instance in X_f:\n",
        "    time = instance[0]\n",
        "    stock_price = instance[1]\n",
        "    stock_price = int(stock_price.item())\n",
        "    time = int(time.item() * 200)\n",
        "\n",
        "    u_collocation_val = torch.Tensor(\n",
        "        np.array([np.round(option_fde_prices[stock_price, time], 3)])\n",
        "    ).type(torch.FloatTensor)\n",
        "    u_collocation.append(u_collocation_val)\n",
        "\n",
        "u_collocation = np.array(u_collocation)\n",
        "u_collocation = np.reshape(u_collocation, (-1, 1))\n",
        "u_collocation = torch.Tensor(u_collocation).type(torch.FloatTensor)\n",
        "print(u_collocation.shape)\n",
        "\n",
        "f_collocation = torch.zeros(N_f, 1)\n",
        "u_boundary = torch.zeros(N_b, 1)\n",
        "\n",
        "# Initializing the PDE solver\n",
        "model1 = BlackScholesMertonModel1()\n",
        "\n",
        "# Original weight initialization didn't change the weights.\n",
        "# Initialize the weights\n",
        "for m in model1.modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Perform backprop\n",
        "MAX_EPOCHS_1 = int(710)\n",
        "LRATE = 8e-3\n",
        "\n",
        "# Use Adam for training\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=LRATE)\n",
        "\n",
        "X_f.requires_grad = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1.to(device)\n",
        "\n",
        "# Send everything to GPU\n",
        "X_f = X_f.to(device)\n",
        "X_b = X_b.to(device)\n",
        "X_exp = X_exp.to(device)\n",
        "u_boundary = u_boundary.to(device)\n",
        "u_exp = u_exp.to(device)\n",
        "u_collocation = u_collocation.to(device)\n",
        "f_collocation = f_collocation.to(device)\n",
        "\n",
        "loss_history_function_1 = []\n",
        "loss_history_f_1 = []\n",
        "loss_history_boundary_1 = []\n",
        "loss_history_exp_1 = []\n",
        "\n",
        "print(\"Learning Rate for this Round of Training :\", LRATE)\n",
        "print(\"First Round of Training\")\n",
        "\n",
        "for epoch in range(MAX_EPOCHS_1):\n",
        "    # Boundary loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_b), device=device)\n",
        "    X_b_shuffle = X_b[rand_index]\n",
        "    u_boundary_shuffle = u_boundary[rand_index]\n",
        "    u_b_pred = model1(X_b_shuffle)\n",
        "    mse_u_b = torch.nn.MSELoss()(u_b_pred, u_boundary_shuffle)\n",
        "\n",
        "    # Expiration time loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_exp), device=device)\n",
        "    X_exp_shuffle = X_exp[rand_index]\n",
        "    u_exp_shuffle = u_exp[rand_index]\n",
        "    u_exp_pred = model1(X_exp_shuffle)\n",
        "    u_exp_pred = u_exp_pred.to(device)\n",
        "    mse_u_exp = torch.nn.MSELoss()(u_exp_pred, u_exp_shuffle)\n",
        "\n",
        "    # Collocation loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_f), device=device)\n",
        "    X_f_shuffle = X_f[rand_index]\n",
        "    f_collocation_shuffle = f_collocation[rand_index]\n",
        "    u_collocation_shuffle = u_collocation[rand_index]\n",
        "    u_pred = model1(X_f_shuffle)\n",
        "    stock_price = X_f_shuffle[:, 1:2]\n",
        "\n",
        "    u_pred_first_partials = torch.autograd.grad(u_pred.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dt = u_pred_first_partials[:, 0:1]\n",
        "    u_pred_ds = u_pred_first_partials[:, 1:2]\n",
        "\n",
        "    u_pred_second_partials = torch.autograd.grad(u_pred_ds.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dss = u_pred_second_partials[:, 1:2]\n",
        "\n",
        "    f_pred = u_pred_dt + (0.5 * (sigma ** 2) * (stock_price ** 2) * u_pred_dss) + ((r - dividend) * stock_price * u_pred_ds) - (r * u_pred)\n",
        "    f_true = f_collocation_shuffle\n",
        "    mse_f = 100 * torch.nn.MSELoss()(f_pred, f_true)\n",
        "    loss = mse_f + mse_u_exp + mse_u_b\n",
        "    mse_function = torch.nn.MSELoss()(u_pred, u_collocation_shuffle).detach()\n",
        "\n",
        "    # Optimizer step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_history_f_1.append(mse_f / 100)\n",
        "    loss_history_boundary_1.append(mse_u_b)\n",
        "    loss_history_exp_1.append(mse_u_exp)\n",
        "    loss_history_function_1.append(mse_function)\n",
        "\n",
        "    if (epoch % 10) == 0:\n",
        "        print(\"- - - - - - - - - - - - - - -\")\n",
        "        print(\"Epoch :\", epoch)\n",
        "        print(f\"Loss Residual: {loss_history_f_1[-1]:.4f}\")\n",
        "        print(f\"Loss Boundary: {loss_history_boundary_1[-1]:.4f}\")\n",
        "        print(f\"Loss Expiration: {loss_history_exp_1[-1]:.4f}\")\n",
        "        print(f\"Loss Function: {loss_history_function_1[-1]:.4f}\")\n",
        "\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "MAX_EPOCHS_2 = int(4700)\n",
        "LRATE = 1e-3\n",
        "\n",
        "# Use Adam for training\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=LRATE)\n",
        "\n",
        "loss_history_function_2 = []\n",
        "loss_history_f_2 = []\n",
        "loss_history_boundary_2 = []\n",
        "loss_history_exp_2 = []\n",
        "\n",
        "print(\"Learning Rate for this Round of Training :\", LRATE)\n",
        "print(\"Second Round of Training\")\n",
        "\n",
        "for epoch in range(MAX_EPOCHS_2):\n",
        "    # Boundary loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_b), device=device)\n",
        "    X_b_shuffle = X_b[rand_index]\n",
        "    u_boundary_shuffle = u_boundary[rand_index]\n",
        "    u_b_pred = model1(X_b_shuffle)\n",
        "    mse_u_b = torch.nn.MSELoss()(u_b_pred, u_boundary_shuffle)\n",
        "\n",
        "    # Expiration time loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_exp), device=device)\n",
        "    X_exp_shuffle = X_exp[rand_index]\n",
        "    u_exp_shuffle = u_exp[rand_index]\n",
        "    u_exp_pred = model1(X_exp_shuffle)\n",
        "    u_exp_pred = u_exp_pred.to(device)\n",
        "    mse_u_exp = torch.nn.MSELoss()(u_exp_pred, u_exp_shuffle)\n",
        "\n",
        "    # Collocation loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_f), device=device)\n",
        "    X_f_shuffle = X_f[rand_index]\n",
        "    f_collocation_shuffle = f_collocation[rand_index]\n",
        "    u_collocation_shuffle = u_collocation[rand_index]\n",
        "    u_pred = model1(X_f_shuffle)\n",
        "    stock_price = X_f_shuffle[:, 1:2]\n",
        "\n",
        "    u_pred_first_partials = torch.autograd.grad(u_pred.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dt = u_pred_first_partials[:, 0:1]\n",
        "    u_pred_ds = u_pred_first_partials[:, 1:2]\n",
        "\n",
        "    u_pred_second_partials = torch.autograd.grad(u_pred_ds.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dss = u_pred_second_partials[:, 1:2]\n",
        "\n",
        "    f_pred = u_pred_dt + (0.5 * (sigma ** 2) * (stock_price ** 2) * u_pred_dss) + ((r - dividend) * stock_price * u_pred_ds) - (r * u_pred)\n",
        "    f_true = f_collocation_shuffle\n",
        "    mse_f = 100 * torch.nn.MSELoss()(f_pred, f_true)\n",
        "    loss = mse_f + mse_u_exp + mse_u_b\n",
        "    mse_function = torch.nn.MSELoss()(u_pred, u_collocation_shuffle).detach()\n",
        "\n",
        "    # Optimizer step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    for m in model1.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            print(m.weight.grad)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_history_f_2.append(mse_f / 100)\n",
        "    loss_history_boundary_2.append(mse_u_b)\n",
        "    loss_history_exp_2.append(mse_u_exp)\n",
        "    loss_history_function_2.append(mse_function)\n",
        "\n",
        "    if (epoch % 10) == 0:\n",
        "        print(\"- - - - - - - - - - - - - - -\")\n",
        "        print(\"Epoch :\", epoch)\n",
        "        print(f\"Loss Residual: {loss_history_f_2[-1]:.4f}\")\n",
        "        print(f\"Loss Boundary: {loss_history_boundary_2[-1]:.4f}\")\n",
        "        print(f\"Loss Expiration: {loss_history_exp_2[-1]:.4f}\")\n",
        "        print(f\"Loss Function: {loss_history_function_2[-1]:.4f}\")\n",
        "\n",
        "print(\"----------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "isqwm619wlqm",
        "outputId": "9a06d561-97ec-4e04-f62d-ff585dc2975e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'option_fde_prices' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-81185875d945>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     u_collocation_val = torch.Tensor(\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption_fde_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstock_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     ).type(torch.FloatTensor)\n\u001b[1;32m     67\u001b[0m     \u001b[0mu_collocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_collocation_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'option_fde_prices' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoJexOcKw5Nt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}