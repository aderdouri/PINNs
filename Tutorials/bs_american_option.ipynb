{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderdouri/PINNs/blob/master/Tutorials/bs_american_option.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Quintus-Zhang/Ferret.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0u5mZLmKOI3",
        "outputId": "cd895f5c-1f6c-4676-86e9-46647f8feeb6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Ferret'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Total 70 (delta 0), reused 0 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (70/70), 222.05 KiB | 7.40 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BLAP2KL9b3y8",
        "outputId": "93d0e03b-d358-4210-b714-ee721aaadde3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7838f9b847b0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Path to the cloned repository\n",
        "repo_path = os.path.join(os.getcwd(), \"Ferret\")\n",
        "\n",
        "# Add the repository path to sys.path\n",
        "sys.path.append(repo_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJyct4xTLPNe",
        "outputId": "3d43e8bf-8469-4245-ddb2-88e26d7f357b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/usr/local/lib/python3.10/dist-packages/setuptools/_vendor', '/root/.ipython', '/content/Ferret']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ExplicitEu import ExplicitEu\n",
        "from ImplicitEu import ImplicitEu\n",
        "from ImplicitAm import ImplicitAmBer\n",
        "from ImplicitAm import ImplicitAmBre"
      ],
      "metadata": {
        "id": "BLbwX8NSKivr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackScholesMertonModel1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BlackScholesMertonModel1, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(2)\n",
        "        self.fc1 = nn.Linear(2, 50)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "        self.fc3 = nn.Linear(50, 50)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm1d(50)\n",
        "        self.fc4 = nn.Linear(50, 50)\n",
        "        self.act4 = nn.ReLU()\n",
        "        self.bn5 = nn.BatchNorm1d(50)\n",
        "        self.fc5 = nn.Linear(50, 50)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.bn6 = nn.BatchNorm1d(50)\n",
        "        self.fc6 = nn.Linear(50, 50)\n",
        "        self.act6 = nn.ReLU()\n",
        "        self.bn7 = nn.BatchNorm1d(50)\n",
        "        self.fc7 = nn.Linear(50, 50)\n",
        "        self.act7 = nn.ReLU()\n",
        "        self.bn8 = nn.BatchNorm1d(50)\n",
        "        self.fc8 = nn.Linear(50, 50)\n",
        "        self.act8 = nn.ReLU()\n",
        "        self.bn9 = nn.BatchNorm1d(50)\n",
        "        self.fc9 = nn.Linear(50, 50)\n",
        "        self.act9 = nn.ReLU()\n",
        "        self.bn10 = nn.BatchNorm1d(50)\n",
        "        self.fc10 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.act4(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.act5(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.act6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.act7(x)\n",
        "        x = self.fc8(x)\n",
        "        x = self.act8(x)\n",
        "        x = self.fc9(x)\n",
        "        x = self.act9(x)\n",
        "        x = self.fc10(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eVk_SonNweRT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from ExplicitEu import ExplicitEu\n",
        "#from ImplicitEu import ImplicitEu\n",
        "#from ImplicitAm import ImplicitAmBer\n",
        "#from ImplicitAm import ImplicitAmBre\n",
        "\n",
        "S0 = 100\n",
        "exercise_price = 100\n",
        "sigma = 0.4\n",
        "r = 0.03\n",
        "dividend = 0.00\n",
        "tau = 3\n",
        "M = 500  # S\n",
        "N = 600  # t\n",
        "Smax = 500\n",
        "is_call = True\n",
        "N_b = 100\n",
        "N_exp = 1000\n",
        "N_f = 10000\n",
        "lb = [0, 0]\n",
        "ub = [500, tau]\n",
        "\n",
        "t, S = np.meshgrid(np.linspace(0, 1, N + 1), np.linspace(0, Smax, M + 1))\n",
        "option = ImplicitAmBer(S0, exercise_price, r, tau, sigma, Smax, M, N, is_call)\n",
        "option.price()\n",
        "option_fde_prices = option.grid\n",
        "\n",
        "def initialize_data(N_b, N_exp, N_f, lb, ub, exercise_price, tau):\n",
        "    # Data for collocation\n",
        "    stock_price_collocation = torch.randint(low=0, high=ub[0] + 1, size=(N_f, 1)).type(torch.FloatTensor)\n",
        "    time_collocation = (torch.randint(low=0, high=100 * ub[1] + 1, size=(N_f, 1)) / 100).type(torch.FloatTensor)\n",
        "\n",
        "    stock_price_mean = torch.mean(stock_price_collocation)\n",
        "    stock_price_std = torch.std(stock_price_collocation)\n",
        "    time_mean = torch.mean(time_collocation)\n",
        "    time_std = torch.std(time_collocation)\n",
        "\n",
        "    time_collocation = (time_collocation - time_mean) / time_std\n",
        "    stock_price_collocation = (stock_price_collocation - stock_price_mean) / stock_price_std\n",
        "\n",
        "    X_f = torch.cat((time_collocation, stock_price_collocation), 1)\n",
        "\n",
        "    # Data for boundary\n",
        "    time_boundary = (torch.randint(low=1, high=100 * ub[1] + 1, size=(N_b, 1)) / 100).type(torch.FloatTensor)\n",
        "    X_b = torch.cat((time_boundary, torch.zeros_like(time_boundary)), 1)\n",
        "\n",
        "    # Data for initial time\n",
        "    stock_price_exp = torch.randint(low=0, high=ub[0] + 1, size=(N_exp, 1)).type(torch.FloatTensor)\n",
        "    option_price_exp = stock_price_exp - exercise_price\n",
        "    u_exp = torch.Tensor([[max(instance, 0)] for instance in option_price_exp]).type(torch.FloatTensor)\n",
        "\n",
        "    X_exp = torch.cat((torch.full_like(stock_price_exp, tau), stock_price_exp), 1)\n",
        "\n",
        "    return X_f, X_f, X_b, X_exp, u_exp\n",
        "\n",
        "X_f, X_f_norm, X_b, X_exp, u_exp = initialize_data(N_b, N_exp, N_f, lb, ub, exercise_price, tau)\n",
        "\n",
        "u_collocation = []\n",
        "for instance in X_f:\n",
        "    time = instance[0]\n",
        "    stock_price = instance[1]\n",
        "    stock_price = int(stock_price.item())\n",
        "    time = int(time.item() * 200)\n",
        "\n",
        "    u_collocation_val = torch.Tensor(\n",
        "        np.array([np.round(option_fde_prices[stock_price, time], 3)])\n",
        "    ).type(torch.FloatTensor)\n",
        "    u_collocation.append(u_collocation_val)\n",
        "\n",
        "u_collocation = np.array(u_collocation)\n",
        "u_collocation = np.reshape(u_collocation, (-1, 1))\n",
        "u_collocation = torch.Tensor(u_collocation).type(torch.FloatTensor)\n",
        "print(u_collocation.shape)\n",
        "\n",
        "f_collocation = torch.zeros(N_f, 1)\n",
        "u_boundary = torch.zeros(N_b, 1)\n",
        "\n",
        "# Initializing the PDE solver\n",
        "model1 = BlackScholesMertonModel1()\n",
        "\n",
        "# Original weight initialization didn't change the weights.\n",
        "# Initialize the weights\n",
        "for m in model1.modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Perform backprop\n",
        "MAX_EPOCHS_1 = int(710)\n",
        "LRATE = 8e-3\n",
        "\n",
        "# Use Adam for training\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=LRATE)\n",
        "\n",
        "X_f.requires_grad = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1.to(device)\n",
        "\n",
        "# Send everything to GPU\n",
        "X_f = X_f.to(device)\n",
        "X_b = X_b.to(device)\n",
        "X_exp = X_exp.to(device)\n",
        "u_boundary = u_boundary.to(device)\n",
        "u_exp = u_exp.to(device)\n",
        "u_collocation = u_collocation.to(device)\n",
        "f_collocation = f_collocation.to(device)\n",
        "\n",
        "loss_history_function_1 = []\n",
        "loss_history_f_1 = []\n",
        "loss_history_boundary_1 = []\n",
        "loss_history_exp_1 = []\n",
        "\n",
        "print(\"Learning Rate for this Round of Training :\", LRATE)\n",
        "print(\"First Round of Training\")\n",
        "\n",
        "for epoch in range(MAX_EPOCHS_1):\n",
        "    # Boundary loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_b), device=device)\n",
        "    X_b_shuffle = X_b[rand_index]\n",
        "    u_boundary_shuffle = u_boundary[rand_index]\n",
        "    u_b_pred = model1(X_b_shuffle)\n",
        "    mse_u_b = torch.nn.MSELoss()(u_b_pred, u_boundary_shuffle)\n",
        "\n",
        "    # Expiration time loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_exp), device=device)\n",
        "    X_exp_shuffle = X_exp[rand_index]\n",
        "    u_exp_shuffle = u_exp[rand_index]\n",
        "    u_exp_pred = model1(X_exp_shuffle)\n",
        "    u_exp_pred = u_exp_pred.to(device)\n",
        "    mse_u_exp = torch.nn.MSELoss()(u_exp_pred, u_exp_shuffle)\n",
        "\n",
        "    # Collocation loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_f), device=device)\n",
        "    X_f_shuffle = X_f[rand_index]\n",
        "    f_collocation_shuffle = f_collocation[rand_index]\n",
        "    u_collocation_shuffle = u_collocation[rand_index]\n",
        "    u_pred = model1(X_f_shuffle)\n",
        "    stock_price = X_f_shuffle[:, 1:2]\n",
        "\n",
        "    u_pred_first_partials = torch.autograd.grad(u_pred.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dt = u_pred_first_partials[:, 0:1]\n",
        "    u_pred_ds = u_pred_first_partials[:, 1:2]\n",
        "\n",
        "    u_pred_second_partials = torch.autograd.grad(u_pred_ds.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dss = u_pred_second_partials[:, 1:2]\n",
        "\n",
        "    f_pred = u_pred_dt + (0.5 * (sigma ** 2) * (stock_price ** 2) * u_pred_dss) + ((r - dividend) * stock_price * u_pred_ds) - (r * u_pred)\n",
        "    f_true = f_collocation_shuffle\n",
        "    mse_f = 100 * torch.nn.MSELoss()(f_pred, f_true)\n",
        "    loss = mse_f + mse_u_exp + mse_u_b\n",
        "    mse_function = torch.nn.MSELoss()(u_pred, u_collocation_shuffle).detach()\n",
        "\n",
        "    # Optimizer step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_history_f_1.append(mse_f / 100)\n",
        "    loss_history_boundary_1.append(mse_u_b)\n",
        "    loss_history_exp_1.append(mse_u_exp)\n",
        "    loss_history_function_1.append(mse_function)\n",
        "\n",
        "    if (epoch % 10) == 0:\n",
        "        print(\"- - - - - - - - - - - - - - -\")\n",
        "        print(\"Epoch :\", epoch)\n",
        "        print(f\"Loss Residual: {loss_history_f_1[-1]:.4f}\")\n",
        "        print(f\"Loss Boundary: {loss_history_boundary_1[-1]:.4f}\")\n",
        "        print(f\"Loss Expiration: {loss_history_exp_1[-1]:.4f}\")\n",
        "        print(f\"Loss Function: {loss_history_function_1[-1]:.4f}\")\n",
        "\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "MAX_EPOCHS_2 = int(4700)\n",
        "LRATE = 1e-3\n",
        "\n",
        "# Use Adam for training\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=LRATE)\n",
        "\n",
        "loss_history_function_2 = []\n",
        "loss_history_f_2 = []\n",
        "loss_history_boundary_2 = []\n",
        "loss_history_exp_2 = []\n",
        "\n",
        "print(\"Learning Rate for this Round of Training :\", LRATE)\n",
        "print(\"Second Round of Training\")\n",
        "\n",
        "for epoch in range(MAX_EPOCHS_2):\n",
        "    # Boundary loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_b), device=device)\n",
        "    X_b_shuffle = X_b[rand_index]\n",
        "    u_boundary_shuffle = u_boundary[rand_index]\n",
        "    u_b_pred = model1(X_b_shuffle)\n",
        "    mse_u_b = torch.nn.MSELoss()(u_b_pred, u_boundary_shuffle)\n",
        "\n",
        "    # Expiration time loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_exp), device=device)\n",
        "    X_exp_shuffle = X_exp[rand_index]\n",
        "    u_exp_shuffle = u_exp[rand_index]\n",
        "    u_exp_pred = model1(X_exp_shuffle)\n",
        "    u_exp_pred = u_exp_pred.to(device)\n",
        "    mse_u_exp = torch.nn.MSELoss()(u_exp_pred, u_exp_shuffle)\n",
        "\n",
        "    # Collocation loss\n",
        "    with torch.no_grad():\n",
        "        rand_index = torch.randperm(len(X_f), device=device)\n",
        "    X_f_shuffle = X_f[rand_index]\n",
        "    f_collocation_shuffle = f_collocation[rand_index]\n",
        "    u_collocation_shuffle = u_collocation[rand_index]\n",
        "    u_pred = model1(X_f_shuffle)\n",
        "    stock_price = X_f_shuffle[:, 1:2]\n",
        "\n",
        "    u_pred_first_partials = torch.autograd.grad(u_pred.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dt = u_pred_first_partials[:, 0:1]\n",
        "    u_pred_ds = u_pred_first_partials[:, 1:2]\n",
        "\n",
        "    u_pred_second_partials = torch.autograd.grad(u_pred_ds.sum(), X_f_shuffle, create_graph=True, allow_unused=True)[0]\n",
        "    u_pred_dss = u_pred_second_partials[:, 1:2]\n",
        "\n",
        "    f_pred = u_pred_dt + (0.5 * (sigma ** 2) * (stock_price ** 2) * u_pred_dss) + ((r - dividend) * stock_price * u_pred_ds) - (r * u_pred)\n",
        "    f_true = f_collocation_shuffle\n",
        "    mse_f = 100 * torch.nn.MSELoss()(f_pred, f_true)\n",
        "    loss = mse_f + mse_u_exp + mse_u_b\n",
        "    mse_function = torch.nn.MSELoss()(u_pred, u_collocation_shuffle).detach()\n",
        "\n",
        "    # Optimizer step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    for m in model1.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            print(m.weight.grad)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_history_f_2.append(mse_f / 100)\n",
        "    loss_history_boundary_2.append(mse_u_b)\n",
        "    loss_history_exp_2.append(mse_u_exp)\n",
        "    loss_history_function_2.append(mse_function)\n",
        "\n",
        "    if (epoch % 10) == 0:\n",
        "        print(\"- - - - - - - - - - - - - - -\")\n",
        "        print(\"Epoch :\", epoch)\n",
        "        print(f\"Loss Residual: {loss_history_f_2[-1]:.4f}\")\n",
        "        print(f\"Loss Boundary: {loss_history_boundary_2[-1]:.4f}\")\n",
        "        print(f\"Loss Expiration: {loss_history_exp_2[-1]:.4f}\")\n",
        "        print(f\"Loss Function: {loss_history_function_2[-1]:.4f}\")\n",
        "\n",
        "print(\"----------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "isqwm619wlqm",
        "outputId": "7b6c513b-8beb-41a5-bff8-fe5449d9b34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 1])\n",
            "Learning Rate for this Round of Training : 0.008\n",
            "First Round of Training\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 0\n",
            "Loss Residual: 5.0028\n",
            "Loss Boundary: 33.0102\n",
            "Loss Expiration: 372824.6250\n",
            "Loss Function: 34481.4141\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 10\n",
            "Loss Residual: 0.1025\n",
            "Loss Boundary: 0.2011\n",
            "Loss Expiration: 9930.9775\n",
            "Loss Function: 34100.3203\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 20\n",
            "Loss Residual: 0.0320\n",
            "Loss Boundary: 0.0483\n",
            "Loss Expiration: 1407.9370\n",
            "Loss Function: 34074.8398\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 30\n",
            "Loss Residual: 0.0127\n",
            "Loss Boundary: 0.3004\n",
            "Loss Expiration: 1237.4965\n",
            "Loss Function: 34166.9531\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 40\n",
            "Loss Residual: 0.0148\n",
            "Loss Boundary: 0.7390\n",
            "Loss Expiration: 1199.8383\n",
            "Loss Function: 34237.2305\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 50\n",
            "Loss Residual: 0.0183\n",
            "Loss Boundary: 0.5712\n",
            "Loss Expiration: 1031.1508\n",
            "Loss Function: 34203.5391\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 60\n",
            "Loss Residual: 0.0234\n",
            "Loss Boundary: 0.4394\n",
            "Loss Expiration: 819.5494\n",
            "Loss Function: 34208.7070\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 70\n",
            "Loss Residual: 0.0097\n",
            "Loss Boundary: 0.4198\n",
            "Loss Expiration: 920.5892\n",
            "Loss Function: 34190.0391\n",
            "- - - - - - - - - - - - - - -\n",
            "Epoch : 80\n",
            "Loss Residual: 0.0055\n",
            "Loss Boundary: 0.0120\n",
            "Loss Expiration: 951.9919\n",
            "Loss Function: 34060.3711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoJexOcKw5Nt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}